{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5adb88ab",
   "metadata": {},
   "source": [
    "# Prueba chill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a9cbf58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding creado para Cristian\n",
      "Embedding creado para Dan Peralta\n",
      "Embedding creado para Jimmy\n",
      "Identidad detectada: Jimmy con similitud 0.895\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os\n",
    "\n",
    "# Inicialización\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "mtcnn = MTCNN(image_size=160, margin=20, keep_all=False, device=device)\n",
    "model = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n",
    "\n",
    "# Función para obtener embedding de una imagen\n",
    "def get_embedding(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    face = mtcnn(img)\n",
    "    if face is None:\n",
    "        raise ValueError(f\"No se detectó rostro en la imagen {img_path}\")\n",
    "    face = face.unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        embedding = model(face).cpu().numpy()\n",
    "    embedding = embedding / np.linalg.norm(embedding)  # Normalizar\n",
    "    return embedding\n",
    "\n",
    "# Crear base de datos de embeddings a partir de carpeta con imágenes de personas\n",
    "def create_database(folder_path):\n",
    "    database = {}\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            person_name = os.path.splitext(filename)[0]\n",
    "            img_path = os.path.join(folder_path, filename)\n",
    "            try:\n",
    "                emb = get_embedding(img_path)\n",
    "                database[person_name] = emb\n",
    "                print(f\"Embedding creado para {person_name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error con {filename}: {e}\")\n",
    "    return database\n",
    "\n",
    "# Función para reconocer persona en imagen de prueba\n",
    "def recognize_face(img_path, database, threshold=0.5):\n",
    "    emb = get_embedding(img_path)\n",
    "    max_sim = -1\n",
    "    identity = \"Desconocido\"\n",
    "\n",
    "    for name, db_emb in database.items():\n",
    "        sim = cosine_similarity(emb, db_emb)[0][0]  # Similaridad coseno\n",
    "        if sim > max_sim:\n",
    "            max_sim = sim\n",
    "            identity = name\n",
    "\n",
    "    if max_sim < threshold:\n",
    "        identity = \"Desconocido\"\n",
    "\n",
    "    return identity, max_sim\n",
    "\n",
    "def main():\n",
    "    # Ruta a carpeta con imágenes de personas conocidas\n",
    "    known_folder = 'personas_conocidas'\n",
    "    database = create_database(known_folder)\n",
    "\n",
    "    # Imagen a reconocer\n",
    "    test_image = 'jimmy.jpg'\n",
    "    identidad, similitud = recognize_face(test_image, database)\n",
    "\n",
    "    print(f\"Identidad detectada: {identidad} con similitud {similitud:.3f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24bdff9",
   "metadata": {},
   "source": [
    "# Ver con cámara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fe27de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base cargada con 13 personas.\n",
      "Reconocimiento facial en tiempo real. Presiona 'q' para salir.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Selección automática de dispositivo (GPU o CPU)\n",
    "device = torch.device( 'cpu')\n",
    "\n",
    "# Inicialización de MTCNN para detección facial\n",
    "mtcnn = MTCNN(image_size=160, margin=20, keep_all=True, device=device)\n",
    "\n",
    "# Modelo para extracción de embeddings faciales\n",
    "model = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n",
    "\n",
    "def get_embedding(face_img):\n",
    "    \"\"\"\n",
    "    Recibe tensor [3,160,160] con imagen RGB normalizada.\n",
    "    Retorna embedding facial normalizado.\n",
    "    \"\"\"\n",
    "    face_img = face_img.unsqueeze(0).to(device)  # Añadir batch y enviar a device\n",
    "    with torch.no_grad():\n",
    "        embedding = model(face_img).cpu().numpy()\n",
    "    embedding = embedding / np.linalg.norm(embedding)\n",
    "    return embedding\n",
    "\n",
    "def recognize_face(embedding, database, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Compara embedding con base de datos y devuelve nombre e índice de similitud.\n",
    "    \"\"\"\n",
    "    max_sim = -1\n",
    "    identity = \"Desconocido\"\n",
    "    for name, db_emb in database.items():\n",
    "        sim = cosine_similarity(embedding, db_emb)[0][0]\n",
    "        if sim > max_sim:\n",
    "            max_sim = sim\n",
    "            identity = name\n",
    "    if max_sim < threshold:\n",
    "        identity = \"Desconocido\"\n",
    "    return identity, max_sim\n",
    "\n",
    "def main():\n",
    "    # Cargar base de datos guardada\n",
    "    database = np.load('database_embeddings.npy', allow_pickle=True).item()\n",
    "    print(f\"Base cargada con {len(database)} personas.\")\n",
    "\n",
    "    cap = cv2.VideoCapture(0)  # Ajusta índice según cámara (0,1,...)\n",
    "    if not cap.isOpened():\n",
    "        print(\"No se pudo abrir la cámara.\")\n",
    "        return\n",
    "\n",
    "    print(\"Reconocimiento facial en tiempo real. Presiona 'q' para salir.\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error al capturar frame de cámara.\")\n",
    "            break\n",
    "\n",
    "        img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        boxes, _ = mtcnn.detect(img_rgb)\n",
    "\n",
    "        if boxes is not None:\n",
    "            h, w, _ = img_rgb.shape\n",
    "            for box in boxes:\n",
    "                try:\n",
    "                    # Limitar coordenadas dentro de la imagen\n",
    "                    x1, y1, x2, y2 = [int(b) for b in box]\n",
    "                    x1, y1 = max(0, x1), max(0, y1)\n",
    "                    x2, y2 = min(w, x2), min(h, y2)\n",
    "                    if x2 <= x1 or y2 <= y1:\n",
    "                        continue  # bounding box inválido, saltar\n",
    "\n",
    "                    # Recortar y preparar imagen para embedding\n",
    "                    face_img = img_rgb[y1:y2, x1:x2]\n",
    "                    face_img = cv2.resize(face_img, (160, 160))\n",
    "                    face_tensor = torch.tensor(face_img).permute(2, 0, 1).float() / 255.0\n",
    "\n",
    "                    # Obtener embedding y reconocer persona\n",
    "                    embedding = get_embedding(face_tensor)\n",
    "                    name, similarity = recognize_face(embedding, database)\n",
    "\n",
    "                    # Dibujar rectángulo y texto en imagen original\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                    cv2.putText(frame, f\"{name} ({similarity:.2f})\", (x1, y1 - 10),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error procesando rostro: {e}\")\n",
    "                    continue\n",
    "\n",
    "        cv2.imshow('Reconocimiento Facial', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a5e364",
   "metadata": {},
   "source": [
    "# Generar DataBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72fc251b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando Alan.jpg...\n",
      "Procesando Alvaro.jpg...\n",
      "Procesando Cristian.jpg...\n",
      "Procesando Dan Peralta.jpg...\n",
      "Procesando Emma.jpg...\n",
      "Procesando Jenifer.jpg...\n",
      "Procesando Jimmy.jpg...\n",
      "Procesando Loli.jpg...\n",
      "Procesando Lucy.jpg...\n",
      "Procesando Manola.jpg...\n",
      "Procesando Melany.jpg...\n",
      "Procesando Sasha.jpg...\n",
      "Procesando Sergio.jpg...\n",
      "Base de datos con 13 embeddings guardada en 'database_embeddings.npy'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "\n",
    "# Selección automática de dispositivo (GPU o CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Inicialización de MTCNN para detección facial\n",
    "mtcnn = MTCNN(image_size=160, margin=20, keep_all=False, device=device)  # keep_all=False porque asumimos una cara por imagen\n",
    "\n",
    "# Modelo para extraer los embebbings\n",
    "model = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n",
    "\n",
    "def get_embedding(face_img):\n",
    "    \"\"\"\n",
    "    Recibe tensor [3,160,160] con imagen RGB normalizada.\n",
    "    Retorna embedding facial normalizado (numpy array).\n",
    "    \"\"\"\n",
    "    face_img = face_img.unsqueeze(0).to(device)  # Añadir batch y enviar a device\n",
    "    with torch.no_grad():\n",
    "        embedding = model(face_img).cpu().numpy()\n",
    "    embedding = embedding / np.linalg.norm(embedding)\n",
    "    return embedding\n",
    "\n",
    "def load_image(path):\n",
    "    img = cv2.imread(path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"No se pudo leer la imagen {path}\")\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img_rgb\n",
    "\n",
    "def process_person_images(folder_path):\n",
    "    database = {}\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            path = os.path.join(folder_path, filename)\n",
    "            print(f\"Procesando {filename}...\")\n",
    "            img_rgb = load_image(path)\n",
    "\n",
    "            # Detectar la cara (solo una por imagen)\n",
    "            face_tensor = mtcnn(img_rgb)\n",
    "            if face_tensor is None:\n",
    "                print(f\"No se detectó cara en {filename}. Se omitirá.\")\n",
    "                continue\n",
    "\n",
    "            # Obtener embedding \n",
    "            embedding = get_embedding(face_tensor)\n",
    "\n",
    "            # Usar el nombre de archivo sin extensión como clave (puedes modificar según estructura)\n",
    "            person_name = os.path.splitext(filename)[0]\n",
    "            database[person_name] = embedding\n",
    "\n",
    "    return database\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    folder = \"personas_conocidas\"\n",
    "    database_embeddings = process_person_images(folder)\n",
    "\n",
    "    # Guardar la base de datos de embeddings\n",
    "    np.save('database_embeddings.npy', database_embeddings)\n",
    "    print(f\"Base de datos con {len(database_embeddings)} embeddings guardada en 'database_embeddings.npy'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094d4551",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
